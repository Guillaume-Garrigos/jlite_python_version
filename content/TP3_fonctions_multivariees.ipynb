{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP3 : Fonctions à plusieurs variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Un petit tour sur les fonctions quadratiques\n",
    "\n",
    "Considérons une fonction quadratique de $\\mathbb{R}^2$ générique, de la forme\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{2}\\langle Ax,x \\rangle + \\langle b,x \\rangle + c.\n",
    "$$\n",
    "\n",
    "Cette fonction dépend d'une matrice \n",
    "$A = \\begin{pmatrix}\n",
    "    A_{11} & A_{12} \\\\\n",
    "    A_{21} & A_{22}\n",
    "\\end{pmatrix}$,\n",
    "d'un vecteur $b = \\begin{pmatrix}\n",
    "    b_{1} \\\\\n",
    "    b_{2}\n",
    "\\end{pmatrix}$, \n",
    "et d'une constante $c \\in \\mathbb{R}$, que l'on supposera toujours nulle, pour simplifier.\n",
    "\n",
    "Essayons de voir à quoi ressemblent ces fonctions quadratiques :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "from scripts.nice_functions import widget_quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_quadratic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devriez voir apparaitre une parabole en 3D, avec des boutons manipulables. Si ce n'est pas le cas, c'est certainement que vous n'êtes pas sur mybinder.org, voir [la page du TP](https://gitlab.math.univ-paris-diderot.fr/garrigos/l3optim-tp/-/blob/master/README.md).\n",
    "\n",
    "Le graphe que vous voyez est celui d'une fonction quadratique. Vous pouvez:\n",
    "- Cliquer sur le graphe et le déplacer pour changer l'angle de la caméra\n",
    "- Manipuler les boutons au-dessus du graphe pour modifier les coefficients de $A$ et $b$ déterminant la fonction quadratique\n",
    "- Selon votre PC il se pourrait qu'il y ait des incompatibilités de résolution et que l'image soit trop petite/grande. Vous pouvez modifier sa taille en tirant sur le petit triangle gris en bas à droite.\n",
    "\n",
    "**I.1)** Amusez-vous un peu avec cet outil, et profitez-en pour vous forger une opinion sur les points suivants:\n",
    "- Observer à quoi ressemble le graphe lorsque la matrice $A$ est définie positive, positive, non définie, négative ou définie négative. \n",
    "- Que constatez-vous lorsque $A$ est antisymétrique? Comment l'expliquez-vous?\n",
    "- Quelles propriétés faut-il que $A$ vérifie pour que la fonction $f$ aie un unique minimiseur?\n",
    "- Quelles propriétés faut-il que $A$ vérifie pour que la fonction $f$ aie au moins minimiseur? Etes-vous sûrs?\n",
    "- Trouver $A$ symétrique et $b$ tels que $b \\notin Im(A)$. Que constatez-vous? Pouvez-vous l'expliquer par un résultat du cours?\n",
    "- Trouver des matrices $A$ positives (non définies poitives) telles que $(0,0)$ soit: un minimiseur global, un maximiseur local, ni l'un ni l'autre. \n",
    "- Pour quelles valeurs de $A$ et $b$ la fonction $f$ est-elle convexe? strictement convexe? Pouvez-vous l'expliquer par un résultat du cours?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I.2)** On s'intéresse maintenant aux *courbes de niveau* d'une fonction. Etant donné une fonction $f : \\mathbb{R}^N \\longrightarrow \\mathbb{R}$, les courbes/ensembles de niveau de $f$ sont tous les ensembles\n",
    "\n",
    "$$\n",
    "[f = r] := \\{ x \\in \\mathbb{R}^N \\ | \\ f(x) = r \\}, \\text{ où } r \\in \\mathbb{R}.\n",
    "$$\n",
    "\n",
    "Vous êtes certainement familiers avec les courbes de niveau en cartographie, qui permettent de représenter les variations de l'élévation/altitude dans un montagne ou une vallée.\n",
    "\n",
    "|  |  |\n",
    "| --- | --- |\n",
    "| ![](https://uncailloudanslachaussure.ch/wp-content/uploads/2019/02/imagesqsq-2-d3bf9.jpg) | ![](https://uncailloudanslachaussure.ch/wp-content/uploads/2019/02/IMG_3418.jpg) |\n",
    "| | Utilisation des courbes de niveau en cartographie ([Source](https://uncailloudanslachaussure.ch/courbes-de-niveau/)) |\n",
    "\n",
    "\n",
    "On peut également dessiner ces ensembles de niveau pour les fonctions de $\\mathbb{R}^2$ dans $\\mathbb{R}$. Intéressons-nous pour l'instant aux fonctions quadratiques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_quadratic(graph=True, levelset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quoi ressemblent les courbes de niveau au voisinage de $(0,0)$ lorsque $(0,0)$ est un minimiseur? Un point selle critique? Un point selle non critique?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I.3)** On s'intéresse maintenant au gradient de notre fonction $f : \\mathbb{R}^2 \\longrightarrow \\mathbb{R}$, qui est une fonction $\\nabla f : \\mathbb{R}^2 \\longrightarrow \\mathbb{R}^2$. \n",
    "\n",
    "**Attention:** prenez garde à ne pas confondre $\\nabla f(x)$, le gradient de $f$ en un point $x$, qui est un vecteur, et $\\nabla f$ qui est une fonction.\n",
    "\n",
    "Les applications de $\\mathbb{R}^N$ dans lui-même sont parfois appelées *champ de vecteurs*, ce qui explique pourquoi on parle parfois de *champ gradient* pour désigner $\\nabla f$. \n",
    "On parle de champ car une façon bien commode de représenter un champ gradient dans $\\mathbb{R}^N$ est de tracer en un nombre fini de points $x_1, \\dots, x_p$ la direction dans laquelle pointe $\\nabla f(x_i)$.\n",
    "\n",
    "| | Champs de vecteurs : illustration | |\n",
    "| --- | --- | --- |\n",
    "| ![](images/vf1.png) | ![](images/vf2.png) | ![](images/vf3.png) |\n",
    "\n",
    "Regardons à quoi cela corrrespond pour nos fonctions quadratiques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_quadratic(gradient=True, levelset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A quoi ressemble le champ gradient au voisinage des points critiques?\n",
    "- Que pouvez-vous dire de l'orientation des flèches représentant le gradient, lorsqu'on les compare aux courbes de niveau?\n",
    "- Imaginez que ces flèches représentent le déplacement, l'écoulement d'un liquide, et que vous êtes une particule suivant le flot, ou une feuille d'arbre qui flotte sur ce liquide (c'est la minute physique/poésie de ce TP). \n",
    "    * Da façon générale, comment varie la valeur de la fonction $f$ lorsque vous vous déplacez?\n",
    "    * Ou cela vous emporte-il? Vous considèrerez en particulier le cas d'une matrice *définie négative*.\n",
    "    * Quel lien pouvez-vous faire avec votre observation concernant les courbes de niveau?\n",
    "\n",
    "|  |\n",
    "| --- |\n",
    "| ![](images/flot.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I.4)** Ce que l'on a observé précédemment nous suggère que *remonter* le flot (c'est-à-dire parcourir le flot en arrière) engendré par le champ de gradient permet de se déplacer en direction des minimiseurs (s'il y en a). \n",
    "\n",
    "Ce que l'on veut donc faire, c'est regarder des trajectoires $x(t) \\in \\mathbb{R}^2$ qui se déplacent dans le temps, et telles qu'en tout point leur dérivée ponctuelle $\\dot x(t)$ soit égal à $- \\nabla f(x(t))$ (on met un $-$ puisque on veut remonter le flot).\n",
    "\n",
    "Autrement dit, on s'intéresse aux trajectoires solutions de l'équation différentielle suivante, qu'on appelle *l'équation du flot gradient*: \n",
    "\n",
    "$$\n",
    "\\dot x(t) = - \\nabla f(x(t)), \\ x(0) = x_0 .\n",
    "$$\n",
    "\n",
    "Va-t-on résoudre cette équation différentielle? Non. Peut-on visualiser ses solutions (approximatives) grâce au calcul? Oui:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_quadratic(graph=True, levelset=True,  flow=True, density=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Arrivez-vous à lire les trajectoires du flot gradient? \n",
    "- Vers où se dirigent ces trajectoires? Dans le cas défini positif? Dans le cas non défini?\n",
    "\n",
    "\n",
    "En pratique, on ne calcule jamais les solutions exactes de cette équation différentielle $\\dot x(t) = - \\nabla f(x(t))$, car il est souvent impossible d'en trouver une solution explicite.\n",
    "\n",
    "Par contre, on se satisfait tout à fait de calculer une suite de points qui *approxime* cette trajectoire. Pour cela, on remplace cette équation différentielle \"en temps continu\" par une relation de récurrence \"en temps discret\":\n",
    "\n",
    "$$\n",
    "\\frac{x_{t+1} - x_t}{\\rho} = - \\nabla f(x_t), \\ \\rho \\sim 0,\n",
    "$$\n",
    "\n",
    "où $\\rho$ est un nombre positif \"petit\", que l'on appelle le **pas** de l'algorithme (*stepsize* en anglais).\n",
    "On peut réécrire  cette relation de récurrence comme: \n",
    "\n",
    "$$\n",
    "x_{t+1} = x_t - \\rho \\nabla f(x_t), \\ \\rho \\sim 0.\n",
    "$$\n",
    "\n",
    "C'est ce que l'on appelle **l'algorithme du gradient**, que l'on étudiera en cours, et que l'on reverra plus tard en TP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Approximation quadratique des fonctions\n",
    "\n",
    "Maintenant que l'on est bien familier avec les fonctions quadratiques de $\\mathbb{R}^2$, intéréssons-nous aux fonctions de $\\mathbb{R}^2$ quelconques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.nice_functions import plot2d_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considérons la fonction $f(x,y) = 2\\sin(x/2)\\sin(y)$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Waves(z):\n",
    "    x,y = z\n",
    "    return 2*np.sin(x/2)*np.sin(y)\n",
    "\n",
    "plt.figure()\n",
    "plot2d_function(Waves, graph=True, levelset=True, plot_box=[[-6,6],[-6,6]], grid_size=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculez à la main $\\nabla f(\\bar x)$ et $\\nabla^2 f(\\bar x)$ en $\\bar x = (\\pi, -\\pi/2)$.\n",
    "- A quoi ressemble la fonction quadratique $f(x)  = \\frac{1}{2}\\langle \\nabla^2 f(\\bar x)x,x \\rangle + \\langle \\nabla f(\\bar x), x \\rangle$? Que constatez-vous?\n",
    "- Même questions en $\\bar x = (0,0)$.\n",
    "- Quel résultat vous permet de justifier ce que vous voyez?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**II.2)** Voici une nouvelle fonction, que l'on appelle également la selle de singe: $f(x,y) = \\frac{1}{3}x^3 - xy^2$.\n",
    "En vous inspirant du code de la question précédente, afficher son graphe sur $[-2,2]^2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Monkey(z):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme précédemment :\n",
    "- En inspectant visuellement le graphe, comment qualifieriez-vous le point $\\bar x = (0,0)$?\n",
    "- Calculez à la main $\\nabla f(x)$ et $\\nabla^2 f(x)$ en $\\bar x = (0,0)$.\n",
    "- A quoi ressemble la fonction quadratique $f(x)  = \\frac{1}{2}\\langle \\nabla^2 f(\\bar x)x,x \\rangle + \\langle \\nabla f(\\bar x), x \\rangle$? \n",
    "- Comment expliquez-vous ce qui se passe? (Dans cette situation on dit que le point critique est **dégénéré**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**II.3)** Le fait que l'on puisse approcher toute fonction lisse par une fonction quadratique donnée par sa hessienne et son gradient est très utile lorsque l'on recherche des minimiseurs!\n",
    "\n",
    "En effet, si l'on dispose d'un point $x$ qui n'est pas un minimiseur, et que l'on cherche ce dernier (ce qui est difficile), une idée consiste à se dire:\n",
    "\n",
    "1. remplaçons notre fonction $f$ par son approximation quadratique en $x$, car au voisinage de $x$ ce sont les mêmes\n",
    "2. minimisons cette approximation quadratique (c'est facile), et remplaçons $x$ par le minimiseur de cette approximation quadratique.\n",
    "\n",
    "En répétant plusieurs fois cette opération, on espère se rapprocher du minimiseur!\n",
    "\n",
    "| Approximations quadratiques successives |\n",
    "| --- |\n",
    "| ![](images/newton_graph.png) |\n",
    "| En $x_0$, on approxime la fonction $f$ (en noir) par une quadratique de Taylor (en bleu). Le minimiseur de cette quadratique est $x_1$, point en lequel on peut de nouveau calculer une approximation quadratique de Taylor (en rose). Son minimiseur est $x_2$, et on pourrait continuer ainsi de suite jusqu'à converger vers le minimiseur de $f$. |\n",
    "\n",
    "\n",
    "Donc, concrètement, on construit une suite de candidats $x_k$ ainsi:\n",
    "\n",
    "1. On calcule l'approximation quadratique de $f$ en $x_k$. Le théorème de Taylor nous dit que pour $h$ petit on a\n",
    "$$\n",
    "f(x_k+h) \\simeq q(h) := f(x_k) + \\langle \\nabla f(x_k) , h \\rangle + \\frac{1}{2} \\langle \\nabla^2f(x_k)h,h \\rangle.\n",
    "$$\n",
    "2. On doit prendre $x_{k+1} = x_k + h$ où $h$ minimise $q$. Or la condition d'optimalité du premier ordre pour cette fonction quadratique $q$ nous dit que $\\nabla f(x_k) + \\nabla^2f(x_k)h = 0$. Autrement dit, $ h = - \\nabla^2f(x_k)^{-1} \\nabla f(x_k)$ si la hessienne est inversible. On aboutit alors à la relation de récurrence:\n",
    "\n",
    "$$\n",
    "x_{k+1} = x_k - \\rho \\nabla^2f(x_k)^{-1} \\nabla f(x_k), \\ \\rho >0.\n",
    "$$\n",
    "\n",
    "Cette méthode est connue sous le nom de **méthode de Newton** lorsque $\\rho =1$. On l'a vue lors du premier TP, et on en reparlera en cours.\n",
    "\n",
    "Parfois on prend un $\\rho$ plus petit, ce qui est équivalent à prendre un vecteur $h$ plus petit, et permet de meiux respecter le fait que l'approximation quadratique est locale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Pour aller plus loin. Méthode du gradient "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette dernière partie, on va essayer de minimiser la fonction suivante (qui est un cas particulier de ce que l'on appelle une fonction *logistique*) : \n",
    "\n",
    "$$\n",
    "f(x,y) = \\ln(1 + e^{x+y}) + \\ln(1 + e^{y-3x}) + \\ln(1 + e^{-x-2y}).\n",
    "$$\n",
    "\n",
    "A priori, il n'est pas facile de résoudre ce problème par le calcul (avez-vous envie de calculer son gradient puis résoudre $\\nabla f(x,y)=0$?).\n",
    "Je vous propose donc d'essayer deux approches, basées sur deux observations faites dans les parties I. et II.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**III.1)** Ecrire une fonction `Logistique(z)` qui prend en entrée un vecteur $z \\in \\mathbb{R}^2$ de type `array`, et qui renvoie en sortie un nombre réel correspodant à la valeur de $f$ évaluée en $z$. Puis vous afficherez le graphe et les courbes de niveau de cette fonction. Vous pourrez vous inspirer du code présent dans la section II. Vers où se trouve le minimiseur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistique(z):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**III.2)** Nous allons maintenant implémenter l'algorithme du gradient pour essayer de nous diriger vers le minimiseur de $f$. Rappelons que nous l'avons défini par la relation de réccurence:\n",
    "\n",
    "$$\n",
    "x_{t+1} = x_t - \\rho \\nabla f(x_t), \\ \\rho \\sim 0.\n",
    "$$\n",
    "\n",
    "Afin d'implémenter l'algorithme, il nous suffit d'être capable de calculer $\\nabla f(x)$.\n",
    "\n",
    "Or on n'a pas envie de calculer ce gradient à la main! On voudrait plutôt que l'ordinateur s'en chage pour nous. Pour cela, on va faire appel à une librairie de *différenciation automatique*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme son nom subtil le suggère, `autograd` permet de calculer automatiquement le gradient d'une fonction Python `f` telle que  `Logistique` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Logistique\n",
    "df = autograd.grad(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous disposez maintenant d'une fonction python `df` qui prend en entrée un `array` dans $\\mathbb{R}^2$, et renvoie un `array` dans $\\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**III.2.a)** Définir un $z \\in \\mathbb{R}^2$ quelconque, et évaluer $f$ et $df$ en $z$. \n",
    "\n",
    "**Attention**, `autograd` n'aime pas les entiers `int` et ne veut que des réels `float`. En python, les nombres `2` et `2.0` sont différents..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**III.2.b)** Vérifiez que $(0,0)$ n'est pas un minimiseur de $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**III.2.c)** Maintenant que vous savez calculer le gradient de $f$, écrivez une fonction `algogradient` :\n",
    "- qui prend en entrée:\n",
    "    - un point de départ `z0` dans $\\mathbb{R}^2$\n",
    "    - un pas `rho`\n",
    "    - un nombre d'itérations maximal `itermax`\n",
    "- qui calcule `itermax` itérations de la suite définie par $x_{k+1} = x_k - \\rho \\nabla f(x_k)$\n",
    "- qui renvoie la dernière itération calculée\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algogradient(z0, rho, itermax):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**III.2.d)** Faites tourner votre fonction pendant 100 itérations, avec un pas petit ($\\simeq 0.5$) et un point de départ de votre choix. Vérifiez si le point obtenu est un point critique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**III.3)** Vous pouvez visualiser la méthode du gradient appliquée aux fonctions quadratiques, en utilisant ce widget interactif qui vous permet de déplacer le point de départ $z_0 = (x_0,y_0)$ et de changer le pas (*stepsize*) $\\rho$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_quadratic(graph=True, levelset=True,  algo='gradient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observez ce qui se passe lorsque le pas est trop grand\n",
    "- Pour un pas petit, et en présence de minimiseurs, le fait que l'algorithme converge est-il dépendant du point initial?\n",
    "- Même question lorsqu'il n'y a pas de minimiseurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**III.4) BONUS** Vous pouvez essayer de coder également la méthode de Newton mentionnée plus haut! Pour cela tout ce dont vous avez besoin est:\n",
    "- Avoir accès à la Hessienne de $f$.\n",
    "    * Vous avez appris en cours que la hessienne est la jacobienne du gradient : $\\nabla f(x) = J(\\nabla f)(x)$\n",
    "    * la librairie `autograd` dispose d'une fonction `autograd.jacobian` qui vous permet de calculer la jacobienne d'un champ de vecteurs\n",
    "- Trouver à chaque itération un $h$ qui vérifie $\\nabla f(x_k) + \\nabla^2f(x_k)h = 0$. Vous avez déjà vu au TP2 qu'il existe une fonction `np.linalg.solve` pour résoudre des systèmes linéaires.\n",
    "\n",
    "Vous verrez que cette méthode trouve le minimiseur beaucoup plus rapidement, mais qu'elle peut échouer lorsque le point initial est mal choisi, ou si le pas $\\rho$ est trop grand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algonewton(z0, rho, itermax):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**III.5) BONUS** Si vous le souhaitez, vous pouvez visualiser la méthode de Newton appliquée aux fonctions quadratiques, en utilisant ce widget interactif qui vous permet de déplacer le point de départ $z_0 = (x_0,y_0)$ et de changer le pas (*stepsize*) $\\rho$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_quadratic(graph=True, levelset=True,  algo='Newton')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lorsque $\\rho=1$ et $A$ définie positive, combien faut-il d'itérations à la méthode de Newton pour converger? Sauriez-vous l'expliquer?\n",
    "- Lorsque $\\rho <1$ et $A$ non définie, vers quoi converge l'algorithme? Est-ce similaire à ce que vous avez vu pour la méthode du gradient?\n",
    "- Lorsque $\\rho < 1$, comment se comporte l'algorithme lorsque vous changez $A$? Est-ce similaire à ce que vous avez vu pour la méthode du gradient? Sauriez-vous l'expliquer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fin du TP.** Pensez à télécharger votre notebook si vous souhaitez en garder une trace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
